{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TKO_2096 Applications of Data Analysis 2021\n",
    "## Exercise 4\n",
    "\n",
    "Complete the tasks given to you in the letter below. There are cells at the end of this notebook to which you are expected to write your code. Insert markdown cells as needed to describe your solution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dear Data Scientist,\n",
    "\n",
    "I have a task for you that concerns drug molecules and their targets. I have spent a lot of time in a laboratory to measure how strongly potential drug molecules bind to putative target molecules. I do not have enough resources to measure all possible drug-target pairs, so I would like to first predict their affinities and then measure only the most promising ones. I have already managed to create a model which I believe is good for this purpose. Its details are below.\n",
    "\n",
    "- algorithm: K-nearest neighbours regressor\n",
    "- parameters: K=20\n",
    "- training data: full data set\n",
    "\n",
    "The full data set is available as the files `input.data`, `output.data` and `pairs.data` for you to use. The first file contains the features of pairs, whereas the second contains their affinities. The third file contains the identifiers of the drug and target molecules of which the pairs are composed. The files are paired, i.e. the i<sup>*th*</sup> row in each file is about the same pair.\n",
    "\n",
    "I am not able to evaluate how well my model will perform when I will use it to predict the affinities of new drug-target pairs. I need you to evaluate the model for me. There are three distinct situations in which I want to use this model in the future.\n",
    "\n",
    "1. I did not have the resources to measure the affinities of all the known drug-target pairs in the laboratory, so I want to use the model to predict the affinities of the remaining pairs.\n",
    "2. I am confident that I will discover new potential drug molecules in the future, so I will want to use the model to predict their affinities to the currently known targets.\n",
    "3. Because new putative target molecules, too, will likely be identified in the future, I will also want to use the model to predict the affinities between the drug molecules I will discover and the target molecules somebody else will discover in the future.\n",
    "\n",
    "I need to get evaluation results from leave-one-out cross-validation with C-index. Please evaluate the generalisation performance of my model in the three situations and explain why your cross-validation methods are suitable for them.\n",
    "\n",
    "\n",
    "Yours sincerely, \\\n",
    "Bio Scientist\n",
    "\n",
    "\n",
    "PS. Follow all the general exercise guidelines stated in Moodle.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## \n",
    "# This is not a working solution, but it's what I got for now\n",
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries you need.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column and rows\n",
      "Input X: (1500, 2500)\n",
      "Output y: (1500,)\n",
      "Pairs: pairs (1500, 2)\n"
     ]
    }
   ],
   "source": [
    "# Read the data files (input.data, output.data, pairs.data).\n",
    "\n",
    "X_in = np.genfromtxt('input.data',delimiter=\" \")\n",
    "y_in = np.genfromtxt('output.data',delimiter=\" \")\n",
    "pairs_in = pd.read_csv('pairs.data',sep=\" \", header=None).to_numpy()\n",
    "#pairs_in = np.array([[j[1:] for j in a] for a in pairs]).astype(int)\n",
    "\n",
    "print(\"Column and rows\")\n",
    "print(\"Input X:\",X_in.shape)\n",
    "print(\"Output y:\",y_in.shape)\n",
    "print(\"Pairs: pairs\",pairs_in.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set shortener for debuggin'\n",
    "a = len(X_in)\n",
    "#a = 200  # comment out for complete set\n",
    "\n",
    "X = X_in[:a]\n",
    "y = y_in[:a]\n",
    "pairs = pairs_in[:a]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the functions you need to perform the requested cross-validations.\n",
    "\n",
    "def LOO(X):\n",
    "    # Creates a generator for splitting the data to training and test sets\n",
    "    # Regular LOO from earlier excercises\n",
    "    \n",
    "    indices = np.arange(len(X)) # number of splits\n",
    "    \n",
    "    for test_index in indices:\n",
    "        \n",
    "        test_index = indices[test_index]\n",
    "        train_index = np.delete(indices, test_index) # all but 'test_index'\n",
    "\n",
    "        yield train_index, test_index\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "def LeaveNthMemberOut(pairs,n):\n",
    "    # Creates a generator for splitting the data to training and test sets\n",
    "    # Removes the pairs with shared nth member from the training set X\n",
    "    \n",
    "    indices = np.arange(len(pairs)) # number of splits\n",
    "    n = n-1\n",
    "    \n",
    "    for ind in indices:\n",
    "        test_index = ind\n",
    "\n",
    "        train_index = indices[np.logical_not(indices==test_index)] # remove test set from training set\n",
    "        \n",
    "        bad_members_idx = indices[pairs[:,n] == pairs[ind][n]] # pairs where item n is the same   \n",
    "        \n",
    "        # remove pairs where the nth item is the same\n",
    "        train_index = np.setdiff1d(train_index, bad_members_idx, assume_unique = True)\n",
    "        \n",
    "        yield train_index, test_index\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "def LeaveBothMembersOut(pairs):\n",
    "    # Creates a generator for splitting the data to training and test sets\n",
    "    # Removes the pairs with any shared members from the training set X\n",
    "    \n",
    "    indices = np.arange(len(pairs)) # number of splits\n",
    "    \n",
    "    for ind in indices:\n",
    "        test_index = ind\n",
    "\n",
    "        train_index = indices[np.logical_not(indices==test_index)] # remove test set from training set\n",
    "        \n",
    "        first_member_indexes = indices[pairs[:,0] == pairs[ind][0]] # pairs where item 1 is the same\n",
    "        second_member_indexes = indices[pairs[:,1] == pairs[ind][1]] # pairs where item 2 is the same\n",
    "        \n",
    "        # remove pairs where the 1st member is the same\n",
    "        train_index = np.setdiff1d(train_index,first_member_indexes, assume_unique = True)\n",
    "        # remove pairs where the 2nd member is the same\n",
    "        train_index = np.setdiff1d(train_index,second_member_indexes, assume_unique = True) \n",
    "        \n",
    "        yield train_index, test_index\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def LOOCV(X, y, loo, k):\n",
    "    # Regressor fitting and predictions\n",
    "    \n",
    "    pred = np.array([]) # feature predictions\n",
    "    \n",
    "    for train_index, test_index in loo:\n",
    "        \n",
    "        # Progress printout\n",
    "        if (test_index+100) % 100 == 0:\n",
    "            print(test_index+100,\"/\", len(X))\n",
    "            \n",
    "            \n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train = y[train_index]\n",
    "        #y_test = y[test_index] # Remain a mere comment until given purpose!\n",
    "        \n",
    "        \n",
    "        knr = KNeighborsRegressor(n_neighbors=k)\n",
    "        \n",
    "        knr.fit(X_train, y_train)\n",
    "        \n",
    "        pred = np.append(pred, knr.predict(X_test.reshape(1,-1)), axis=0)\n",
    "        \n",
    "    pred = np.array(pred)\n",
    "    \n",
    "    return pred\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def cindex(true_labels, pred_labels):\n",
    "    \"\"\"Returns general C-index between true labels and predicted labels\"\"\"  \n",
    "    \n",
    "    N = 0\n",
    "    T = 0 # Total number of unequal outputs\n",
    "    \n",
    "    ## Create the data set\n",
    "    data = np.column_stack((true_labels.reshape(-1,1), pred_labels))\n",
    "    \n",
    "    \n",
    "    for i in range(len(data)): # First item of a pair\n",
    "        for j in range(i, len(data)): # Second item of a pair\n",
    "            \n",
    "            if (np.greater(data[i][0],data[j][0]) and (np.greater(data[i][1],data[j][1]))):\n",
    "                N = N + 1\n",
    "            elif (np.greater(data[j][0],data[i][0]) and (np.greater(data[j][1],data[i][1]))):\n",
    "                N = N + 1\n",
    "            elif (np.not_equal(data[i][0],data[j][0]) and (np.equal(data[i][1],data[j][1]))):\n",
    "                N = N + 0.5\n",
    "                \n",
    "            if np.not_equal(data[i][0],data[j][0]):\n",
    "                T = T + 1\n",
    "\n",
    "    \n",
    "    return N/T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run cross-validations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 / 1500\n",
      "200 / 1500\n",
      "300 / 1500\n",
      "400 / 1500\n",
      "500 / 1500\n",
      "600 / 1500\n",
      "700 / 1500\n",
      "800 / 1500\n",
      "900 / 1500\n",
      "1000 / 1500\n",
      "1100 / 1500\n",
      "1200 / 1500\n",
      "1300 / 1500\n",
      "1400 / 1500\n",
      "1500 / 1500\n",
      "Predictions took 00:00:32!\n",
      "\n",
      "C-index = 0.7753800149970941 \n",
      "\n",
      "All done! Took 00:00:44!\n"
     ]
    }
   ],
   "source": [
    "# Run the requested cross-validations and print the results.\n",
    "\n",
    "# Situation 1, new pair of existing drugs and targets\n",
    "# Both members (drug and target) in the test set are shared with observations in the training set\n",
    "# Type A observation\n",
    "# Type A observation's dependencies are similar to what can be found in a regular Leave-One-Out\n",
    "# Regular Leave-One-Out can be used\n",
    "\n",
    "s = time.time()\n",
    "\n",
    "loo = LOO(pairs) # Pairwise LOO generator\n",
    "\n",
    "k = 20\n",
    "predictions = LOOCV(X,y,loo,k) # params: X, y, loo generator, k\n",
    "\n",
    "e = time.time()\n",
    "print(f\"Predictions took {time.strftime('%H:%M:%S', time.gmtime(round(e-s,2)))}!\")\n",
    "\n",
    "c1 = cindex(y, predictions) # Calculation of C-index\n",
    "print(\"\\nC-index =\",c1,\"\\n\")  \n",
    "\n",
    "e = time.time()\n",
    "print(f\"All done! Took {time.strftime('%H:%M:%S', time.gmtime(round(e-s,2)))}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 / 1500\n",
      "200 / 1500\n",
      "300 / 1500\n",
      "400 / 1500\n",
      "500 / 1500\n",
      "600 / 1500\n",
      "700 / 1500\n",
      "800 / 1500\n",
      "900 / 1500\n",
      "1000 / 1500\n",
      "1100 / 1500\n",
      "1200 / 1500\n",
      "1300 / 1500\n",
      "1400 / 1500\n",
      "1500 / 1500\n",
      "Predictions took 00:00:32!\n",
      "\n",
      "C-index = 0.765166223904048 \n",
      "\n",
      "All done! Took 00:00:44!\n"
     ]
    }
   ],
   "source": [
    "# Situation 2, completely new drug or target molecule\n",
    "# One of the members is found in the training set\n",
    "# Observation types B and C\n",
    "# Cannot use regular LOO to avoid too optimistic dependencies\n",
    "# The shared member must be removed from the training set to avoid bias\n",
    "\n",
    "s = time.time()\n",
    "\n",
    "n = 2 # for shared second member, targets \n",
    "loo = LeaveNthMemberOut(pairs, n) # Pairwise LOO generator\n",
    "\n",
    "k = 20\n",
    "predictions = LOOCV(X,y,loo,k) # params: X, y, loo generator, k\n",
    "\n",
    "e = time.time()\n",
    "print(f\"Predictions took {time.strftime('%H:%M:%S', time.gmtime(round(e-s,2)))}!\")\n",
    "\n",
    "c2 = cindex(y, predictions) # Calculation of C-index\n",
    "print(\"\\nC-index =\",c2,\"\\n\")  \n",
    "\n",
    "e = time.time()\n",
    "print(f\"All done! Took {time.strftime('%H:%M:%S', time.gmtime(round(e-s,2)))}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 / 1500\n",
      "200 / 1500\n",
      "300 / 1500\n",
      "400 / 1500\n",
      "500 / 1500\n",
      "600 / 1500\n",
      "700 / 1500\n",
      "800 / 1500\n",
      "900 / 1500\n",
      "1000 / 1500\n",
      "1100 / 1500\n",
      "1200 / 1500\n",
      "1300 / 1500\n",
      "1400 / 1500\n",
      "1500 / 1500\n",
      "Predictions took 00:00:32!\n",
      "\n",
      "C-index = 0.6763313587770585 \n",
      "\n",
      "All done! Took 00:00:44!\n"
     ]
    }
   ],
   "source": [
    "# Situation 3, both, the drug and the target, are new\n",
    "# Neither of the pair members are found in the training set\n",
    "# Type D observation\n",
    "# Cannot use regular LOO or LeavePairOut\n",
    "\n",
    "s = time.time()\n",
    "\n",
    "loo = LeaveBothMembersOut(pairs) # Pairwise LOO generator\n",
    "\n",
    "k = 20\n",
    "predictions = LOOCV(X,y,loo,k) # params: X, y, loo generator, k\n",
    "\n",
    "e = time.time()\n",
    "print(f\"Predictions took {time.strftime('%H:%M:%S', time.gmtime(round(e-s,2)))}!\")\n",
    "\n",
    "c3 = cindex(y, predictions) # Calculation of C-index\n",
    "print(\"\\nC-index =\",c3,\"\\n\")  \n",
    "\n",
    "e = time.time()\n",
    "print(f\"All done! Took {time.strftime('%H:%M:%S', time.gmtime(round(e-s,2)))}!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpret results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C-index result result for situation 1: 0.7753800149970941\n",
      "C-index result for situation 2: 0.765166223904048\n",
      "C-index result for situation 3: 0.6763313587770585\n"
     ]
    }
   ],
   "source": [
    "# Interpret the results you obtained and explain why your cross-validation methods work.\n",
    "print(\"C-index result result for situation 1:\",c1)\n",
    "print(\"C-index result for situation 2:\",c2)\n",
    "print(\"C-index result for situation 3:\",c3)\n",
    "\n",
    "# Explanations for methods are within the spesific functions\n",
    "\n",
    "# C-index is dropping since the model knows less and less of the data it's trying to predict. \n",
    "# Situation 1 is the best since no data was omitted\n",
    "# Situation 2 is close to sit. 1 since it had some of the same data to learn from\n",
    "# Situation 3 had none of that so it's noticeably worse (0.1) than the other two cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
